{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**캘리포니아 주 주택 가격 예측 시스템에 대한 실습 내용을 토대로 다음 과제를 수행하세요. 수업 중 다룬 실습 내용의 코드 중 필요한 코드를 가져다 추가하시기 바랍니다.**\n",
        "\n",
        "**제출 결과물:** <font color=\"red\"> 본인이 작성한 코드 및 주어진 질문에 대한 답이 작성된 .ipynb 파일을 제출하세요 </font>(**파일명: 학번.ipynb**). <font color=\"red\"> 또한 과제 평가 시 확인할 수 있도록 본인이 작성한 코드 실행결과가 저장된 상태의 .ipynb 파일을 반드시 제출해야 합니다. </font>"
      ],
      "metadata": {
        "id": "FKqFICqU0BFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1."
      ],
      "metadata": {
        "id": "KK88P8gkrUNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kernel=\"linear\"(하이퍼파라미터 C에 대해 다양한 값 설정 가능) 또는 kernel=\"rbf\"(하이퍼파라미터 C 및 gamma에 대해 다양한 값 설정 가능)와 같은 다양한 하이퍼파라미터를 갖는 Support Vector Machine (SVM) regressor (sklearn.svm.SVR)를 사용해보세요. SVM regressor는 데이터셋 사이즈에 대한 확장성이 떨어져서 대규모 데이터셋을 학습하는데 효과적이지 못하므로 훈련셋의 처음 5,000개 샘플들에 대해서만 모델을 훈련하고 3-fold 교차 검증만 수행하도록 합니다. 교차 검증 시 성능 측정 지표로는 RMSE를 사용하도록 합니다. 아래 주어진 코드는 그리드 탐색을 이용하여 최적의 하이퍼파라미터 값 조합을 찾기 위한 코드의 일부입니다. param_grid에 명시된 하이퍼파라미터들에 대해서 최적의 값 조합을 찾을 수 있도록 아래 주어진 코드를 완성하고 다음 두가지 세부 질문에 대한 답을 작성해서 제출하시오.\n",
        "\n",
        "\n",
        "세부 질문:\n",
        "\n",
        "1.   그리드 탐색을 통해 찾은 최적의 하이퍼파라미터 조합은 무엇인가요?\n",
        "2.   최적의 하이퍼파라미터 조합일 때 SVM regressor 모델의 RMSE는 무엇인가요?"
      ],
      "metadata": {
        "id": "QjhyDa1NrFWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuY8xxrsqlWB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "문제 1에 대해 주어진 코드\n",
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "param_grid = [\n",
        "        {'svr__kernel': ['linear'], 'svr__C': [10., 30., 100., 300., 1000.,\n",
        "                                               3000., 10000., 30000.0]},\n",
        "        {'svr__kernel': ['rbf'], 'svr__C': [1.0, 3.0, 10., 30., 100., 300.,\n",
        "                                            1000.0],\n",
        "         'svr__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2."
      ],
      "metadata": {
        "id": "J8xTMG4n1yVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 랜덤 탐색을 이용한 하이퍼파라미터 튜닝 과정을 구현해보세요. 아래 주어진 코드는 랜덤 탐색을 이용하여 최적의 하이퍼파라미터 값 조합을 찾기 위한 코드의 일부입니다. param_distribs에 명시된 하이퍼파라미터들에 대해서 최적의 값 조합을 찾을 수 있도록 아래 주어진 코드를 완성하고 다음 두가지 세부 질문에 대한 답을 작성해서 제출하시오.\n",
        "\n",
        "\n",
        "세부 질문:\n",
        "\n",
        "1.   랜덤 탐색을 통해 찾은 최적의 하이퍼파라미터 조합은 무엇인가요?\n",
        "2.   최적의 하이퍼파라미터 조합일 때 SVM regressor 모델의 RMSE는 무엇인가요?"
      ],
      "metadata": {
        "id": "FuEOy1g811bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "문제 2에 대해 주어진 코드\n",
        "\"\"\"\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import expon, reciprocal\n",
        "\n",
        "# see https://docs.scipy.org/doc/scipy/reference/stats.html\n",
        "# for `expon()` and `reciprocal()` documentation and more probability distribution functions.\n",
        "\n",
        "# Note: gamma is ignored when kernel is \"linear\"\n",
        "param_distribs = {\n",
        "        'svr__kernel': ['linear', 'rbf'],\n",
        "        'svr__C': reciprocal(20, 200_000),\n",
        "        'svr__gamma': expon(scale=1.0),\n",
        "    }\n",
        "\n",
        "\"\"\"\n",
        "Randomized Search 설정: n_iter=20, cv=3, random_state=42 로 설정할 것\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3CQTkgGWRXtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3."
      ],
      "metadata": {
        "id": "FFun0qtXrGBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 주어진 코드는 표준화 특성 스케일링을 구현한 `StandardScalerClone` 커스텀 변환기 클래스 코드입니다. 다음 추가 구현 요구사항을 만족하도록 `StandardScalerClone` 커스텀 변환기 클래스를 확장 구현하세요.\n",
        "\n",
        "\n",
        "*   `scaler.inverse_transform(scaler.fit_transform(X))`을 실행하면 `X`에 매우 가까운 배열이 반환되도록 `inverse_transform()` 메서드를 추가 구현하세요.\n",
        "*   `fit()` 메서드 호출 시 입력이 데이터프레임인 경우 `fit()` 메서드에서 `feature_names_in_`이 설정되어야 합니다. `feature_names_in_`은 입력 데이터프레임의 column name들에 대한 NumPy 배열이 되어야 합니다.\n",
        "\n",
        "\n",
        "또한 다음 요구사항을 만족하도록 `get_feature_names_out()` 메서드를 구현하세요.\n",
        "\n",
        "1.   `get_feature_names_out()` 메서드는 optional argement(인자)로 `input_features=None`을 포함하도록 선언합니다.\n",
        "2.   `get_feature_names_out()` 메서드 호출 시 `input_features` 인자로 값이 전달되면 그 길이가 `n_features_in_`과 일치하는지 확인하고, 만약 일치하지 않는다면 ValueError를 발생시키도록 합니다(`raise ValueError(\"error message\")` 아래 주어진 관련 코드 참고)\n",
        "3.   위 2에서 길이가 일치한다면 추가로 `feature_names_in_`이 정의되어 있는지 확인합니다. 만약 정의되어 있으면 `feature_names_in_`과 `input_features`를 비교한 다음 같으면 `input_features`를 반환하고 같지 않으면 ValueError를 발생시키도록 합니다.\n",
        "4.   `get_feature_names_out()` 메서드 호출 시 `input_features` 인자로 값이 전달되지 않은 경우에는 만약 `feature_names_in_`이 정의되어 있다면 `feature_names_in_`을 반환하고, `feature_names_in_`이 정의되지 않은 경우에는 길이가 `n_features_in_`인 `np.array([\"x0\", \"x1\", ...])`를 반환하도록 합니다."
      ],
      "metadata": {
        "id": "Pm253LTtrKCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_array, check_is_fitted\n",
        "\n",
        "class StandardScalerClone(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, with_mean=True):  # no *args or **kwargs!\n",
        "        self.with_mean = with_mean\n",
        "\n",
        "    # 주어진 요구사항 만족하도록 fit()에 코드 추가\n",
        "    def fit(self, X, y=None):  # y is required even though we don't use it\n",
        "        X = check_array(X)  # checks that X is an array with finite float values\n",
        "        self.mean_ = X.mean(axis=0)\n",
        "        self.scale_ = X.std(axis=0)\n",
        "        self.n_features_in_ = X.shape[1]  # every estimator stores this in fit()\n",
        "        return self  # always return self!\n",
        "\n",
        "    def transform(self, X):\n",
        "        check_is_fitted(self)  # looks for learned attributes (with trailing _)\n",
        "        X = check_array(X)\n",
        "        if self.n_features_in_ != X.shape[1]:\n",
        "            raise ValueError(\"Unexpected number of features\")\n",
        "        if self.with_mean:\n",
        "            X = X - self.mean_\n",
        "        return X / self.scale_\n",
        "\n",
        "    # def inverse_transform(self, X):\n",
        "\n",
        "\n",
        "    # def get_feature_names_out(self, input_features=None):"
      ],
      "metadata": {
        "id": "GLUNpQUGq5B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> **중요: 다음 일련의 테스트케이스 코드가 정상적으로 실행될 수 있도록 `StandardScalerClone` 커스텀 변환기 클래스가 구현되어야 합니다.** </font>"
      ],
      "metadata": {
        "id": "JvnjN1xE_48e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.estimator_checks import check_estimator\n",
        "\n",
        "# StandardScalerClone 커스텀 변환기 클래스가 scikit-learn convention에 맞게 구현되었는지 확인\n",
        "check_estimator(StandardScalerClone())"
      ],
      "metadata": {
        "id": "rcXjFbVC_mR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 3)\n",
        "\n",
        "scaler = StandardScalerClone()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "assert np.allclose(X_scaled, (X - X.mean(axis=0)) / X.std(axis=0))"
      ],
      "metadata": {
        "id": "cvULoHsa_o30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScalerClone(with_mean=False)\n",
        "X_scaled_uncentered = scaler.fit_transform(X)\n",
        "\n",
        "assert np.allclose(X_scaled_uncentered, X / X.std(axis=0))"
      ],
      "metadata": {
        "id": "qXBEzwwz_sJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScalerClone()\n",
        "X_back = scaler.inverse_transform(scaler.fit_transform(X))\n",
        "\n",
        "assert np.allclose(X, X_back)"
      ],
      "metadata": {
        "id": "VSw6ZDqsHHD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert np.all(scaler.get_feature_names_out() == [\"x0\", \"x1\", \"x2\"])\n",
        "assert np.all(scaler.get_feature_names_out([\"a\", \"b\", \"c\"]) == [\"a\", \"b\", \"c\"])"
      ],
      "metadata": {
        "id": "WVrVt-i8HLtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"a\": np.random.rand(100), \"b\": np.random.rand(100)})\n",
        "scaler = StandardScalerClone()\n",
        "X_scaled = scaler.fit_transform(df)\n",
        "\n",
        "assert np.all(scaler.feature_names_in_ == [\"a\", \"b\"])\n",
        "assert np.all(scaler.get_feature_names_out() == [\"a\", \"b\"])"
      ],
      "metadata": {
        "id": "B3n9_8cQHPgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}